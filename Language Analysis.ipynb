{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = \"I’ve been 2 times to New York in 2011, but did not have the constitution for it. It DIDN’T appeal to me. I preferred Los Angeles.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [[token.text for token in sentence] for sentence in nlp(\n",
    "documents).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', '’ve', 'been', '2', 'times', 'to', 'New', 'York', 'in', '2011', ',', 'but', 'did', 'not', 'have', 'the', 'constitution', 'for', 'it', '.'], ['It', 'DIDN’T', 'appeal', 'to', 'me', '.'], ['I', 'preferred', 'Los', 'Angeles', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [[token.lemma_ for token in sentence] for sentence in nlp(\n",
    "documents).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-PRON-', 'have', 'be', '2', 'time', 'to', 'New', 'York', 'in', '2011', ',', 'but', 'do', 'not', 'have', 'the', 'constitution', 'for', '-PRON-', '.'], ['-PRON-', 'DIDN’T', 'appeal', 'to', '-PRON-', '.'], ['-PRON-', 'prefer', 'Los', 'Angeles', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = [[stemmer.stem(token) for token in sentence] for sentence in\n",
    "tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 've', 'been', '2', 'time', 'to', 'new', 'york', 'in', '2011', ',', 'but', 'did', 'not', 'have', 'the', 'constitut', 'for', 'it', '.'], ['it', \"didn't\", 'appeal', 'to', 'me', '.'], ['i', 'prefer', 'los', 'angel', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [gram for gram in ngrams(tokens[0], 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', '’ve'), ('’ve', 'been'), ('been', '2'), ('2', 'times'), ('times', 'to'), ('to', 'New'), ('New', 'York'), ('York', 'in'), ('in', '2011'), ('2011', ','), (',', 'but'), ('but', 'did'), ('did', 'not'), ('not', 'have'), ('have', 'the'), ('the', 'constitution'), ('constitution', 'for'), ('for', 'it'), ('it', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [[token.pos_ for token in sentence] for sentence in nlp(\n",
    "documents).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PRON', 'VERB', 'AUX', 'NUM', 'NOUN', 'ADP', 'PROPN', 'PROPN', 'ADP', 'NUM', 'PUNCT', 'CCONJ', 'AUX', 'PART', 'AUX', 'DET', 'NOUN', 'ADP', 'PRON', 'PUNCT'], ['PRON', 'VERB', 'VERB', 'ADP', 'PRON', 'PUNCT'], ['PRON', 'VERB', 'PROPN', 'PROPN', 'PUNCT']]\n"
     ]
    }
   ],
   "source": [
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [[token.text for token in sentence\n",
    "if token.pos_ in {'NOUN', 'VERB', 'PROPN', 'ADJ', 'ADV'}\n",
    "and not token.is_stop]\n",
    "for sentence in nlp(documents).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['times', 'New', 'York', 'constitution'], ['DIDN’T', 'appeal'], ['preferred', 'Los', 'Angeles']]\n"
     ]
    }
   ],
   "source": [
    "print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [[(entity.text, entity.label_)\n",
    "for entity in nlp(sentence.text).ents]\n",
    "for sentence in nlp(documents).sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('2', 'CARDINAL'), ('New York', 'GPE'), ('2011', 'DATE')], [], [('Los Angeles', 'GPE')]]\n"
     ]
    }
   ],
   "source": [
    "print (entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
